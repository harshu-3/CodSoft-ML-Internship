{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import LancasterStemmer\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout, SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_path='/kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/train_data.txt'\n",
    "train_data=pd.read_csv( train_path , sep=':::',engine='python',names=['Title','Genre','Description'])\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path='/kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/test_data.txt'\n",
    "test_data=pd.read_csv( test_path , sep=':::',engine='python',names=['ID', 'Title','Description'])\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "counts = train_data.Genre.value_counts()\n",
    "sns.barplot(x=counts, y=counts.index, orient='h')  \n",
    "plt.xlabel('Genre')\n",
    "plt.ylabel('Count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,8))\n",
    "counts = train_data.Genre.value_counts()\n",
    "sns.barplot(x=counts.index, y=counts, color='blue')\n",
    "plt.xlabel('Genre' ,fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Count', fontsize=14, fontweight='bold')\n",
    "plt.title('Distribution of Genres', fontsize=16, fontweight='bold')\n",
    "plt.xticks(rotation=90, fontsize=14, fontweight='bold');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['length']=train_data['Description'].apply(len)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 7))\n",
    "sns.histplot(data=train_data, x='length', bins=20, kde=True, color='blue')\n",
    "plt.xlabel('Length', fontsize=14, fontweight='bold')\n",
    "plt.ylabel('Frequency', fontsize=14, fontweight='bold')\n",
    "plt.title('Distribution of Lengths', fontsize=16, fontweight='bold')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = LancasterStemmer()\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def clean_text(text):\n",
    "   \n",
    "    text = text.lower()                       \n",
    "    text = re.sub('-',' ',text.lower())  \n",
    "    text = re.sub(f'[{string.digits}]',' ',text)  \n",
    "    text = ' '.join([stemmer.stem(word) for word in text.split() if word not in stop_words])  \n",
    "    text =  re.sub(r'@\\S+', '',text)                   \n",
    "    text =  re.sub(r'http\\S+', '',text)            \n",
    "    text =  re.sub(r'pic.\\S+', '',text) \n",
    "    text =  re.sub(r\"[^a-zA-Z+']\", ' ',text)            \n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', ' ', text+' ')      \n",
    "    text = \"\".join([i for i in text if i not in string.punctuation])\n",
    "    words = nltk.tokenize.word_tokenize(text,language=\"english\", preserve_line=True)\n",
    "    stopwords = nltk.corpus.stopwords.words('english') \n",
    "    text = \" \".join([i for i in words if i not in stopwords and len(i)>2])\n",
    "    text= re.sub(\"\\s[\\s]+\", \" \",text).strip()          \n",
    "    return re.sub(f'[{re.escape(string.punctuation)}]','',text) \n",
    "input_text = \"Certainly you get a dramatic boost from hello bye the the hi -iv iem-k q934*2yee !*3 2e38\"\n",
    "print(f'Original text: {input_text}')\n",
    "print(f'Cleaned text: {clean_text(input_text)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Text_cleaning'] = train_data.Description.apply(clean_text)\n",
    "test_data['Text_cleaning'] = test_data.Description.apply(clean_text)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['length_Text_cleaning']=train_data['Text_cleaning'].apply(len)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(1, 2, 1)\n",
    "original_lengths = train_data['Description'].apply(len)\n",
    "plt.hist(original_lengths, bins=range(0, max(original_lengths) + 100, 100), color='blue', alpha=0.7)\n",
    "plt.title('Original Text Length')\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.subplot(1, 2, 2)\n",
    "cleaned_lengths = train_data['Text_cleaning'].apply(len)\n",
    "plt.hist(cleaned_lengths, bins=range(0, max(cleaned_lengths) + 100, 100), color='green', alpha=0.7)\n",
    "plt.title('Cleaned Text Length')\n",
    "plt.xlabel('Text Length')\n",
    "plt.ylabel('Frequency')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_data['length_Text_cleaning']>2000).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Dataframe size (before removal): ',len(train_data))\n",
    "filt=train_data['length_Text_cleaning']>2000\n",
    "train_data.drop(train_data[filt].index,axis=0,inplace=True)  \n",
    "print('Dataframe size (after removal): ',len(train_data))\n",
    "print(f'Removed rows: {filt.sum()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,5))\n",
    "sns.barplot(x='Genre',y='length_Text_cleaning',data=train_data)  # from 600ish to 350ish -> significant reduction in length\n",
    "plt.xticks(rotation=60)\n",
    "plt.show()\n",
    "plt.figure(figsize=(20,5))\n",
    "sns.boxplot(x=train_data['length_Text_cleaning'].values,hue='Genre',data=train_data)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = 50000\n",
    "max_len = 250\n",
    "tokenizer = Tokenizer(num_words=num_words, filters='!\"#$%&()*+,-./:;<=>?@[\\]^_`{|}~', lower=True)\n",
    "tokenizer.fit_on_texts(train_data['Text_cleaning'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_path='/kaggle/input/genre-classification-dataset-imdb/Genre Classification Dataset/test_data_solution.txt'\n",
    "test_data_solution=pd.read_csv( test_path , sep=':::',engine='python',names=['ID','Title','Genre','Description'])\n",
    "test_data_solution.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tokenizer.texts_to_sequences(train_data['Text_cleaning'].values)\n",
    "X = pad_sequences(X, maxlen=max_len)\n",
    "y = pd.get_dummies(train_data['Genre']).values\n",
    "X_test = tokenizer.texts_to_sequences(test_data['Text_cleaning'].values)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "y_test = pd.get_dummies(test_data_solution['Genre']).values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "model = Sequential()\n",
    "model.add(Embedding(num_words, EMBEDDING_DIM, input_length=X.shape[1]))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.1, recurrent_dropout=0.2))\n",
    "model.add(Dense(27, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_callbacks  = [EarlyStopping(monitor='val_loss',\n",
    "                              min_delta=0,\n",
    "                              patience=2,\n",
    "                              mode='auto')]\n",
    "history = model.fit(X, y, epochs=6, batch_size=32,validation_data=(X_test,y_test), callbacks=my_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.legend()\n",
    "plt.title('Accuracy')\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.legend()\n",
    "plt.title('Loss')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
